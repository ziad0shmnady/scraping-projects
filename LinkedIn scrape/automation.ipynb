{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Create an instance of the Chrome web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to a website\n",
    "driver.get(\"https://www.linkedin.com/login\")\n",
    "# User Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = ''\n",
    "password1 = ''\n",
    "\n",
    "# Find the username and password fields and enter the login credentials\n",
    "user = driver.find_element(\"id\", \"username\")\n",
    "user.send_keys(user_name)\n",
    "password = driver.find_element(\"id\", \"password\")\n",
    "password.send_keys(password1)\n",
    "# Click on the login button\n",
    "log_in_button = driver.find_element(\"class name\", \"login__form_action_container\")\n",
    "log_in_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_name_location_description(driver=driver):\n",
    "    try:\n",
    "        name = driver.find_element(\n",
    "            By.XPATH, \"//h1[@class='text-heading-xlarge inline t-24 v-align-middle break-words']\")\n",
    "        location = driver.find_element(\n",
    "            By.XPATH, \"//span[@class='text-body-small inline t-black--light break-words']\")\n",
    "        description = driver.find_element(\n",
    "            By.XPATH, \"//div[@class='text-body-medium break-words']\")\n",
    "        return name.text, location.text, description.text\n",
    "    except:\n",
    "        return \"No name, location or description found\"\n",
    "\n",
    "# find the current company through xpath using function and try and except\n",
    "\n",
    "\n",
    "def find_current_company(driver=driver):\n",
    "    try:\n",
    "        company = []\n",
    "        jobs = driver.find_element(\n",
    "            By.CSS_SELECTOR, \"ul.pv-text-details__right-panel\")\n",
    "        for job in jobs.find_elements(By.CSS_SELECTOR, \"li\"):\n",
    "            company.append(job.text)\n",
    "        return company\n",
    "    except:\n",
    "        return \"No current company found\"\n",
    "\n",
    "# find the experience through xpath using function and try and except\n",
    "\n",
    "\n",
    "\n",
    "def find_about(driver=driver):\n",
    "    try:\n",
    "        about = driver.find_element(\"xpath\", \"//div[@id='about']\")\n",
    "        # get parent\n",
    "        parent = about.find_element(By.XPATH, \"..\")\n",
    "        span = parent.find_elements(By.TAG_NAME, \"span\")[2]\n",
    "\n",
    "        return span.text\n",
    "    except:\n",
    "        return \"No about found\"\n",
    "# find the education through xpath using function and try and except\n",
    "\n",
    "\n",
    "def find_education(driver=driver):\n",
    "    try:\n",
    "        education = driver.find_element(\"xpath\", \"//div[@id='education']\")\n",
    "        # get parent\n",
    "        parent = education.find_element(By.XPATH, \"..\")\n",
    "        li = parent.find_elements(\n",
    "            By.CSS_SELECTOR, 'ul li .display-flex.flex-row.justify-space-between ')\n",
    "        educationList = []\n",
    "        for i in li:\n",
    "            educationList.append(i.text.split(\"\\n\")[::2])\n",
    "        return educationList\n",
    "    except:\n",
    "        return \"No education found\"\n",
    "# find the skills through xpath using function and try and except\n",
    "\n",
    "\n",
    "def find_skills(driver=driver):\n",
    "    try:\n",
    "        skillList = []\n",
    "        time.sleep(2)\n",
    "        education = driver.find_element(By.CSS_SELECTOR, 'div#skills').find_element(By.XPATH, \"..\")\n",
    "        ul=education.find_element(By.CSS_SELECTOR, 'ul.pvs-list')\n",
    "        li=ul.find_elements(By.CSS_SELECTOR, 'li.artdeco-list__item.CPdrxwLGLHUmTkzfgZRNFPRNGZMqGadE.AYPgCXhbVOBqMSpbRXUEDGDcYRpGgLYPNoRovw')\n",
    "        for i in li:\n",
    "            span=i.find_element(By.CSS_SELECTOR, 'span')\n",
    "            skillList.append(span.text)\n",
    "        return skillList\n",
    "    except:\n",
    "        return []\n",
    "# if profile has experience\n",
    "\n",
    "\n",
    "def have_experience(driver=driver):\n",
    "    try:\n",
    "        experiance = driver.find_element(\"xpath\", \"//div[@id='experience']\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# find only university education through xpath using function and try and except\n",
    "\n",
    "\n",
    "def find_university_education(driver=driver):\n",
    "    try:\n",
    "        educationList = []\n",
    "        time.sleep(2)\n",
    "        education = driver.find_element(By.CSS_SELECTOR, 'div#education').find_element(By.XPATH, \"..\")\n",
    "        ul=education.find_element(By.CSS_SELECTOR, 'ul.pvs-list')\n",
    "        li=ul.find_elements(By.CSS_SELECTOR, 'li.artdeco-list__item.CPdrxwLGLHUmTkzfgZRNFPRNGZMqGadE.AYPgCXhbVOBqMSpbRXUEDGDcYRpGgLYPNoRovw')\n",
    "        for i in li:\n",
    "            span=i.find_element(By.CSS_SELECTOR, 'span')\n",
    "            educationList.append(span.text)\n",
    "        return educationList\n",
    "    except:\n",
    "        return []\n",
    "def find_experience(driver=driver):\n",
    "    try:\n",
    "        educationList = []\n",
    "        time.sleep(2)\n",
    "        education = driver.find_element(By.CSS_SELECTOR, 'div#experience').find_element(By.XPATH, \"..\")\n",
    "        ul=education.find_element(By.CSS_SELECTOR, 'ul.pvs-list')\n",
    "        li=ul.find_elements(By.CSS_SELECTOR, 'li.artdeco-list__item.CPdrxwLGLHUmTkzfgZRNFPRNGZMqGadE.AYPgCXhbVOBqMSpbRXUEDGDcYRpGgLYPNoRovw')\n",
    "        for i in li:\n",
    "            span=i.find_element(By.CSS_SELECTOR, 'span')\n",
    "            educationList.append(span.text)\n",
    "        return educationList\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# find the certifications through xpath using function and try and except\n",
    "\n",
    "\n",
    "def find_certifications(driver=driver):\n",
    "    try:\n",
    "        certificationsList = []\n",
    "        licenses = driver.find_element(\n",
    "            \"xpath\", \"//div[@id='licenses_and_certifications']\")\n",
    "# get parent\n",
    "        parent = licenses.find_element(By.XPATH, \"..\")\n",
    "        li = parent.find_elements(\n",
    "            By.CSS_SELECTOR, 'ul li .display-flex.flex-row.justify-space-between')\n",
    "        for i in li:\n",
    "            certificationsList.extend(i.text.split(\"\\n\")[::2])\n",
    "        return certificationsList\n",
    "    except:\n",
    "        return \"No certifications found\"\n",
    "\n",
    "\n",
    "def separate(df, colName):\n",
    "    df = df.join(pd.DataFrame(df[colName].tolist()).add_prefix(colName))\n",
    "    df.drop(colName, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marketing Communications', 'Corporate Communications']\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.linkedin.com/in/craig-clark-0b30201/\")\n",
    "educationList = []\n",
    "time.sleep(2)\n",
    "education = driver.find_element(By.CSS_SELECTOR, 'div#skills').find_element(By.XPATH, \"..\")\n",
    "ul=education.find_element(By.CSS_SELECTOR, 'ul.pvs-list')\n",
    "li=ul.find_elements(By.CSS_SELECTOR, 'li.artdeco-list__item.CPdrxwLGLHUmTkzfgZRNFPRNGZMqGadE.AYPgCXhbVOBqMSpbRXUEDGDcYRpGgLYPNoRovw')\n",
    "for i in li:\n",
    "    span=i.find_element(By.CSS_SELECTOR, 'span')\n",
    "    educationList.append(span.text)\n",
    "print(educationList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.linkedin.com/in/craig-clark-0b30201/\")\n",
    "name, location, description = find_name_location_description()\n",
    "about=find_about()\n",
    "experiace=find_experience()\n",
    "university=find_university_education()\n",
    "skillsList = find_skills()\n",
    "info = []\n",
    "\n",
    "print(\"-------------------\")\n",
    "info.append({\"name\": name, \"location\": location, \"description\": description,\"about\":about,\"experiace\":experiace,\n",
    " \"university\": university, \"skills\": skillsList})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Craig Clark', 'location': 'Vancouver, British Columbia, Canada', 'description': 'Technology CMO, Top 10 Wealth Management CMO of the Year', 'about': ' I’ve spent much of my career as an independent contributor and marketing leader in the fiercely competitive technology industry and that bag of tricks is highly adaptable to any competitive service business. From driving pipeline creation via a metrics-driven sales development, digital marketing, content marketing and event plan to leading brand transformation, PR strategy and weighing in on your customer experience, I’m a change agent that’s pragmatically focused on growth.\\n\\nMy teams consistently recognize me as both an inspiring leader and a great person to bounce ideas off of. I’ve been successful and have the references to back it up.\\n\\nI was raised on the Naramata Bench in the Okanagan Valley with a diverse pre-corporate career that includes cooking, serving tables and tending vines on a vineyard. I was once a janitor. Yes, a janitor.\\n\\nOn evenings and weekends, I’m a fairly serious fisherman.', 'experiace': ['Chief Marketing Officer', 'Chief Marketing Officer', 'Vice President, Global Marketing & Sales Development', 'Director, CRM Marketing Programs', 'Director, Marketing Communications'], 'university': ['British Columbia Institute of Technology', 'The University of British Columbia'], 'skills': ['Marketing Communications', 'Corporate Communications']}]\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export info to csv\n",
    "df = pd.DataFrame(info)\n",
    "df.to_csv('linkedin.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get company name using function and try and except\n",
    "def get_company_name(driver=driver):\n",
    "    try:\n",
    "        ompany_name = driver.find_element(By.CSS_SELECTOR, \".jobs-unified-top-card__company-name\")\n",
    "        return ompany_name.text\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "def get_location(driver=driver):\n",
    "    try:\n",
    "        location = driver.find_element(By.CSS_SELECTOR, \".jobs-unified-top-card__bullet\")\n",
    "        return location.text\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "def get_type(driver=driver):\n",
    "    try:\n",
    "        type = driver.find_element(By.CSS_SELECTOR, \".jobs-unified-top-card__workplace-type\")\n",
    "        return type.text\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "    \n",
    "def get_description(driver=driver):\n",
    "    try:\n",
    "        parent= driver.find_element(By.CSS_SELECTOR, \".jobs-box--fadein\")\n",
    "        button=parent.find_element(By.CSS_SELECTOR, \"button\")\n",
    "        time.sleep(2)\n",
    "        #click on button\n",
    "        button.click()\n",
    "        description = driver.find_element(By.CSS_SELECTOR, \".jobs-description__content\")\n",
    "        return description.text\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "def get_industry(driver=driver):\n",
    "    try:\n",
    "        div = driver.find_element(By.CSS_SELECTOR, \"div .mt5.mb2\")\n",
    "        ul= div.find_element(By.CSS_SELECTOR, \"ul\")\n",
    "        company=ul.find_element(By.XPATH, \"//li-icon[@type='company']\")\n",
    "        parent=company.find_element(By.XPATH, \"../../../..\")\n",
    "        return parent.text.split(\" · \")[1] \n",
    "    except:\n",
    "        return \"Not found\"\n",
    "    \n",
    "def get_type_work(driver=driver):\n",
    "    try:\n",
    "        div = driver.find_element(By.CSS_SELECTOR, \"div .mt5.mb2\")\n",
    "        ul= div.find_element(By.CSS_SELECTOR, \"ul\")\n",
    "        company=ul.find_element(By.XPATH, \"//li-icon[@type='job']\")\n",
    "        parent=company.find_element(By.XPATH, \"../../../..\")\n",
    "        return parent.text.split(\" · \")[0] \n",
    "    except:\n",
    "        return \"Not found\"\n",
    "\n",
    "def get_skills(driver=driver):\n",
    "    try:\n",
    "        time.sleep(3)\n",
    "        button=driver.find_element(By.CSS_SELECTOR, \".mv5\")\n",
    "        button.click()\n",
    "        time.sleep(3)\n",
    "        ulSkill=driver.find_element(By.CSS_SELECTOR, \"ul.job-details-skill-match-status-list\")\n",
    "        return ulSkill.text.split(\"\\n\")[::2]\n",
    "    except:\n",
    "        return []    \n",
    "\n",
    "def get_jobTitle(driver=driver):\n",
    "    try:\n",
    "        jobTitle=driver.find_element(By.CSS_SELECTOR, \"h1\")\n",
    "        return jobTitle.text\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "\n",
    "def extract_degree_requirement(job_description):\n",
    "    pattern = r\"(?i).*\\b(degree)\\b.*?(?=\\n)\"\n",
    "\n",
    "    match = re.search(pattern, job_description)\n",
    "    if match:\n",
    "        degree_requirement_line = match.group()\n",
    "        return degree_requirement_line.strip()\n",
    "    else:\n",
    "        return ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the Scrape\n",
      "1. Scrape Profiles\n",
      "2. Scrape jobs\n",
      "Select the Country to scrape\n",
      "1. India\n",
      "2. USA\n",
      "3. Lebanon\n",
      "Select the number of profiles to scrape\n",
      "8 25\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16340\\2220241426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_profiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m       \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m       \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_name_location_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Select the Scrape\")\n",
    "print(\"1. Scrape Profiles\")\n",
    "print(\"2. Scrape jobs\")\n",
    "scrape = int(input(\"Enter your scrape \\n\"))\n",
    "\n",
    "if scrape == 1:\n",
    "  #choice which country to scrape\n",
    "  print(\"Select the Country to scrape\")\n",
    "  print(\"1. India\")\n",
    "  print(\"2. USA\")\n",
    "  print(\"3. Lebanon\")\n",
    "  \n",
    "  country=str(input(\"Enter your country Link \\n\"))\n",
    "\n",
    "        #choice number of profiles to scrape\n",
    "  print(\"Select the number of profiles to scrape\")\n",
    "  number_of_profiles=int(input(\"Enter the number of profiles to scrape \\n\"))\n",
    "  profilesFile=pd.read_csv(\"profiles.csv\")\n",
    "  Links=[]\n",
    "  num1 = random.randint(2, 50)\n",
    "  num2 = random.randint(2, 50)\n",
    "  minn=min(num1,num2)\n",
    "  maxn=max(num1,num2)\n",
    "  print(minn,maxn)\n",
    "  for page in range(2,3):\n",
    "    try:\n",
    "        l=country+\"&start=\"+str(page)+\"\"\n",
    "      # Navigate to a website\n",
    "        driver.get(l)\n",
    "        time.sleep(3)\n",
    "        ul = driver.find_element(By.XPATH, \"//ul[@class='reusable-search__entity-result-list list-style-none']\")\n",
    "        li=ul.find_elements(By.TAG_NAME,\"li\")\n",
    "        for i in li:\n",
    "          link=i.find_element(By.TAG_NAME,\"a\")\n",
    "          Links.append(link.get_attribute(\"href\"))\n",
    "    except:\n",
    "      continue\n",
    "  info=[]\n",
    "  counter = len(info)+1\n",
    "  for i in range(0, number_of_profiles):\n",
    "      driver.get(Links[i])\n",
    "      time.sleep(2)\n",
    "      name, location, description = find_name_location_description()\n",
    "      about=find_about()\n",
    "      have_exp=have_experience()\n",
    "      university=find_university_education()\n",
    "      skillsList = find_skills()\n",
    "      print(counter)\n",
    "      counter += 1\n",
    "      print(\"-------------------\")\n",
    "      info.append({\"name\": name, \"location\": location, \"description\": description,\"about\":about,\n",
    "                  \"experiance\": have_exp, \"university\": university, \"skills\": skillsList})\n",
    "  df=pd.DataFrame(info)\n",
    "\n",
    "\n",
    "\n",
    "  skills_seprate= separate(df,'skills')\n",
    "  education_seprate= separate(skills_seprate,'university')      \n",
    "  education_seprate[['degree', 'magor']] = education_seprate['university1'].str.split(',',1, expand=True)\n",
    "  education_seprate.drop('university1', axis=1, inplace=True)\n",
    "  \n",
    "  education_seprate.loc[education_seprate['description'].str.contains('Data Analyst '), 'description'] = 'Data Analyst'\n",
    "  education_seprate.loc[education_seprate['description'].str.contains('Data Engineer '), 'description'] = 'Data Engineer'\n",
    "  education_seprate.loc[education_seprate['description'].str.contains('Data Scientist '), 'description'] = 'Data Scientist'\n",
    "  education_seprate.loc[education_seprate['description'].str.contains('Software'), 'description'] = 'Software Engineer'\n",
    "  education_seprate.loc[education_seprate['location'].str.contains('Lebanon'), 'location'] = 'Lebanon'\n",
    "\n",
    "  pd.concat([profilesFile, education_seprate], axis=0).to_csv('profiles.csv', index=False)\n",
    "elif scrape == 2:\n",
    "    #choice which country to scrape\n",
    "  print(\"Enter The Linke Country to scrape\")\n",
    "\n",
    "  \n",
    "  country=str(input(\"Enter your country Link \\n\"))\n",
    "\n",
    "      #choice number of profiles to scrape\n",
    "  print(\"Select the number of Jobs to scrape\")\n",
    "  number_of_jobs=int(input(\"Enter the number of jobs to scrape \\n\"))\n",
    "  \n",
    "  jobFile=pd.read_csv(\"jobs.csv\")\n",
    "  #get all the job links\n",
    "  link=[]\n",
    "  for i in range(1,14,7):\n",
    "      l=country+\"&start=\"+str(i)+\"\"  \n",
    "      driver.get(l)\n",
    "      # get ul \n",
    "      time.sleep(5)\n",
    "      #scroll down in right side to get all the jobs\n",
    "      driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "      ul = driver.find_element(By.CSS_SELECTOR, \".scaffold-layout__list-container\")\n",
    "\n",
    "      a= ul.find_elements(By.CSS_SELECTOR, \"a\")\n",
    "      for i in a:\n",
    "          link.append(i.get_attribute(\"href\"))\n",
    "  info=[]\n",
    "  counter = len(info)+1\n",
    "  for i in range(0, number_of_jobs):\n",
    "      driver.get(link[i])\n",
    "      time.sleep(2)\n",
    "      jobTitle=get_jobTitle()\n",
    "      company_name = get_company_name()\n",
    "      location = get_location()\n",
    "      type = get_type()\n",
    "      description = get_description()\n",
    "      degree=extract_degree_requirement(description)\n",
    "      industry = get_industry()\n",
    "      type_work = get_type_work()\n",
    "      skills = get_skills()\n",
    "      print(counter)\n",
    "      print(\"skills: \", skills)\n",
    "      counter += 1\n",
    "      print(\"-------------------\")\n",
    "      info.append({\"company_name\": company_name, \"jobTitle\":jobTitle, \"location\": location, \"type\": type,\n",
    "                  \"degree\": degree, \"industry\": industry, \"type_work\": type_work, \"skills\": skills})\n",
    "  df=pd.DataFrame(info)\n",
    "  df['jobTitle'] = df['jobTitle'].str.split().str[:3].str.join(' ')\n",
    "\n",
    "  df.loc[df['degree'].str.contains('Computer'), \"degree\"] = 'degree in Computer Science'\n",
    "  df.loc[df['degree'].str.contains('Engineering'), 'degree'] = 'degree in Engineering'\n",
    "  df.loc[df['degree'].str.contains('Information Technology'), 'degree'] = 'degree in Information Technology'\n",
    "  df.loc[df['degree'].str.contains('language'), 'degree'] = 'degree in language'\n",
    "  df.loc[df['degree'].str.contains('Business'), 'degree'] = 'degree in Business'\n",
    "  df.loc[df['degree'].str.contains('Arts'), 'degree'] = 'degree in Arts'\n",
    "  df.loc[df['degree'].str.contains('Math'), 'degree'] = 'degree in Math'\n",
    "  df.loc[df['degree'].str.contains('Statistics'), 'degree'] = 'degree in Statistics'\n",
    "  df.loc[df['degree'].str.contains('Economics'), 'degree'] = 'degree in Economics'\n",
    "  df.loc[df['degree'].str.contains('Finance'), 'degree'] = 'degree in Finance'\n",
    "  df.loc[df['degree'].str.contains('Accounting'), 'degree'] = 'degree in Accounting'\n",
    "  df.loc[df['degree'].str.contains('Marketing'), 'degree'] = 'degree in Marketing'\n",
    "  df.loc[df['degree'].str.contains('Management'), 'degree'] = 'degree in Management'\n",
    "  df.loc[df['degree'].str.contains('Science'), 'degree'] = 'degree in Computer Science'\n",
    "  df.loc[df['location'].str.contains('Lebanon'), 'location'] = 'Lebanon'\n",
    "\n",
    "                            \n",
    "  def separate(df,colName):\n",
    "    df = df.join(pd.DataFrame(df[colName].tolist()).add_prefix(colName))\n",
    "    df.drop(colName, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "  skills_seprate= separate(df,'skills')\n",
    "  #update jobs csv file by skills_seprate\n",
    "  pd.concat([jobFile, skills_seprate], axis=0).to_csv('jobs.csv', index=False)\n",
    "  #convert data in degree coulmns appreviation to full name\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
